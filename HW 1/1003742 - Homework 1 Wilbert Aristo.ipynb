{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Homework 1\n",
    "\n",
    "### Wilbert Aristo Guntoro - 1003742"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thought Process / Steps:\n",
    "\n",
    "1. **Filter** only **Spring, Summer, and Autumn Images** from the whole dataset\n",
    "2. Keep the labels of each of these images in a dictionary called **ssa_dict** where the **key** is the *filename* and the **value** is the array of labels for each season (e.g. *[1,0,0] for Spring image, [0,1,0] for Summer image, [0,0,1] for Autumn image*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from shutil import copyfile, move, rmtree\n",
    "\n",
    "# Initialise folder\n",
    "spring_summer_autumn = os.path.join(os.getcwd(), \"spring_summer_autumn\")\n",
    "try:\n",
    "    os.makedirs(spring_summer_autumn)\n",
    "except:\n",
    "    rmtree(spring_summer_autumn)\n",
    "    os.makedirs(spring_summer_autumn)\n",
    "\n",
    "ssa_dict = {}\n",
    "\n",
    "with open(\"gtlabels.txt\") as label_file:\n",
    "    for line in label_file:\n",
    "        line_array = line.split()\n",
    "        # If Spring, Summer, or Autumn, then copy that file from collection to a special directory\n",
    "        if int(line_array[10]) or int(line_array[11]) or int(line_array[12]):\n",
    "            filename = line_array[0]\n",
    "            ssa_dict[filename + \"_ft.npy\"] = list(map(int, line_array[10:13]))\n",
    "            copyfile(\"imagefeatures/{}_ft.npy\".format(filename), \"spring_summer_autumn/{}_ft.npy\".format(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Split spring, summer, and autumn images in **alphabetical order** into:\n",
    "- Training Set (First 65% Images)\n",
    "- Validation Set (Next 15% Images)\n",
    "- Test Set (Last 20% Images)\n",
    "\n",
    "I did a **manual splitting** here instead of using sklearn's train_test_split() because manual splitting is easier. There were also **no requirement for me to use train_test_split() or randomise the splitting process** in the homework brief."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spring_summer_autumn_files = os.listdir(spring_summer_autumn)\n",
    "total_files = len(spring_summer_autumn_files)\n",
    "training_number = math.floor(0.65 * total_files)\n",
    "validation_number = math.floor(0.15 * total_files)\n",
    "\n",
    "# Initialise Folders\n",
    "training_folder = os.path.join(spring_summer_autumn, \"train\")\n",
    "validation_folder = os.path.join(spring_summer_autumn, \"validate\")\n",
    "test_folder = os.path.join(spring_summer_autumn, \"test\")\n",
    "\n",
    "os.makedirs(training_folder)\n",
    "os.makedirs(validation_folder)\n",
    "os.makedirs(test_folder)\n",
    "\n",
    "# Do the splitting\n",
    "os.chdir(\"spring_summer_autumn\")\n",
    "\n",
    "for filename in spring_summer_autumn_files[:training_number]:\n",
    "    move(filename, \"train/\" + filename)\n",
    "\n",
    "for filename in spring_summer_autumn_files[training_number:training_number+validation_number]:\n",
    "    move(filename, \"validate/\" + filename)\n",
    "    \n",
    "for filename in spring_summer_autumn_files[training_number+validation_number:]:\n",
    "    move(filename, \"test/\" + filename)\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create BinarySVM class that can train, validate and test data using specified regularization paramater (*reg_param*) and kernel type (*linear*, *rbf*, etc.) <br> We can run the BinarySVM class by calling *execute_on_validation()* method <br> When we are ready to run the SVM on test set, we supply the best *reg_param* and run *execute_on_test()* method instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- VALIDATING Regularization Parameter = 0.01 --------\n",
      "Vanilla Accuracy = 81.871%\n",
      "Class-Wise Averaged Accuracy = 75.355%\n",
      "\n",
      "-------- VALIDATING Regularization Parameter = 0.1 --------\n",
      "Vanilla Accuracy = 77.193%\n",
      "Class-Wise Averaged Accuracy = 56.118%\n",
      "\n",
      "-------- VALIDATING Regularization Parameter = 0.31622776601683794 --------\n",
      "Vanilla Accuracy = 78.363%\n",
      "Class-Wise Averaged Accuracy = 59.226%\n",
      "\n",
      "-------- VALIDATING Regularization Parameter = 1.0 --------\n",
      "Vanilla Accuracy = 77.778%\n",
      "Class-Wise Averaged Accuracy = 56.895%\n",
      "\n",
      "-------- VALIDATING Regularization Parameter = 3.1622776601683795 --------\n",
      "Vanilla Accuracy = 77.778%\n",
      "Class-Wise Averaged Accuracy = 58.449%\n",
      "\n",
      "-------- VALIDATING Regularization Parameter = 10 --------\n",
      "Vanilla Accuracy = 77.778%\n",
      "Class-Wise Averaged Accuracy = 55.341%\n",
      "\n",
      "-------- VALIDATING Regularization Parameter = 100 --------\n",
      "Vanilla Accuracy = 77.778%\n",
      "Class-Wise Averaged Accuracy = 56.895%\n",
      "\n",
      "\u001b[1m From validation above, the best regularization paramater is 0.01\u001b[0m\n",
      "\n",
      "-------- TEST SET WITH Regularization Parameter = 0.01 and Kernel Type = linear --------\n",
      "Vanilla Accuracy = 76.957%\n",
      "Class-Wise Averaged Accuracy = 63.539%\n",
      "\n",
      "-------- TEST SET WITH Regularization Parameter = 0.01 and Kernel Type = rbf --------\n",
      "Vanilla Accuracy = 76.522%\n",
      "Class-Wise Averaged Accuracy = 67.511%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from statistics import mean\n",
    "import numpy as np\n",
    "\n",
    "class BinarySVM:\n",
    "    \n",
    "    def __init__(self, reg_param, kernel_type):\n",
    "        self.reg_param = reg_param\n",
    "        self.kernel_type = kernel_type\n",
    "        self.spring_classifier = None\n",
    "        self.summer_classifier = None\n",
    "        self.autumn_classifier = None\n",
    "        self.vanilla_accuracy = 0\n",
    "        self.classwise_averaged_accuracy = 0\n",
    "    \n",
    "    def init_classifiers(self):\n",
    "        self.spring_classifier = svm.SVC(C=self.reg_param, kernel=self.kernel_type, probability=True)\n",
    "        self.summer_classifier = svm.SVC(C=self.reg_param, kernel=self.kernel_type, probability=True)\n",
    "        self.autumn_classifier = svm.SVC(C=self.reg_param, kernel=self.kernel_type, probability=True)\n",
    "        \n",
    "    def train(self, on_dataset = \"train\"):\n",
    "        os.chdir(\"spring_summer_autumn/{}\".format(on_dataset))\n",
    "\n",
    "        training_X = []\n",
    "        training_spring_y = []\n",
    "        training_summer_y = []\n",
    "        training_autumn_y = []\n",
    "\n",
    "        # Get X values and corresponding labels for spring, summer, autumn\n",
    "        for training_filename in os.listdir(os.getcwd()):\n",
    "            training_X.append(np.load(training_filename))\n",
    "            training_spring_y.append(ssa_dict[training_filename][0])\n",
    "            training_summer_y.append(ssa_dict[training_filename][1])\n",
    "            training_autumn_y.append(ssa_dict[training_filename][2])\n",
    "\n",
    "        # Train each classifier using X values and its respective array of labels (y)\n",
    "        self.spring_classifier.fit(training_X, training_spring_y)\n",
    "        self.summer_classifier.fit(training_X, training_summer_y)\n",
    "        self.autumn_classifier.fit(training_X, training_autumn_y)\n",
    "\n",
    "        os.chdir(\"../..\")\n",
    "    \n",
    "    def test(self, on_dataset = \"validate\"):\n",
    "        os.chdir(\"spring_summer_autumn/{}\".format(on_dataset))\n",
    "\n",
    "        validation_X = []\n",
    "        validation_Y = []\n",
    "        total_spring = 0\n",
    "        total_summer = 0\n",
    "        total_autumn = 0\n",
    "\n",
    "        # Get X values and corresponding labels for spring, summer, autumn\n",
    "        for validation_filename in os.listdir(os.getcwd()):\n",
    "            validation_X.append(np.load(validation_filename))\n",
    "            validation_Y.append(ssa_dict[validation_filename])\n",
    "            if ssa_dict[validation_filename][0]:\n",
    "                total_spring += 1\n",
    "            elif ssa_dict[validation_filename][1]:\n",
    "                total_summer += 1\n",
    "            else:\n",
    "                total_autumn += 1\n",
    "\n",
    "        # Get Prediction\n",
    "        spring_probas = self.spring_classifier.predict_proba(validation_X)\n",
    "        summer_probas = self.summer_classifier.predict_proba(validation_X)\n",
    "        autumn_probas = self.autumn_classifier.predict_proba(validation_X)\n",
    "        \n",
    "        predicted_indexes = []                      \n",
    "        for spring_proba, summer_proba, autumn_proba in zip(spring_probas, summer_probas, autumn_probas):\n",
    "            highest_proba = max([spring_proba[1], summer_proba[1], autumn_proba[1]])\n",
    "            # Store index = 0 if Spring has highest probability\n",
    "            if highest_proba == spring_proba[1]:\n",
    "                predicted_indexes.append(0)\n",
    "            # Store index = 1 if Summer has highest probability\n",
    "            elif highest_proba == summer_proba[1]:\n",
    "                predicted_indexes.append(1)\n",
    "            # Store index = 2 if Autumn has highest probability\n",
    "            else:\n",
    "                predicted_indexes.append(2)\n",
    "        \n",
    "        # Get Vanilla Accuracy\n",
    "        correct_prediction = 0\n",
    "        for index, answer_key in zip(predicted_indexes, validation_Y):\n",
    "            if answer_key[index] == 1:\n",
    "                correct_prediction += 1\n",
    "        \n",
    "        self.vanilla_accuracy = round((correct_prediction / len(validation_Y)) * 100, 3)\n",
    "        \n",
    "        ## ===== Get Class-Wise Averaged Accuracy ====\n",
    "        # We can make use of predicted_indexes to count how many Spring/Summer/Autumn images that we PREDICTED\n",
    "        # We have achieved respective total number of spring, summer and autumn images from above\n",
    "        spring_accuracy = predicted_indexes.count(0) / total_spring\n",
    "        summer_accuracy = predicted_indexes.count(1) / total_summer\n",
    "        autumn_accuracy = predicted_indexes.count(2) / total_autumn\n",
    "        self.classwise_averaged_accuracy = round(mean([spring_accuracy, summer_accuracy, autumn_accuracy]) * 100, 3)\n",
    "        \n",
    "        os.chdir(\"../..\")\n",
    "    \n",
    "    def execute_on_validation(self):\n",
    "        self.init_classifiers()\n",
    "        self.train()\n",
    "        self.test()\n",
    "        print(\"-------- VALIDATING Regularization Parameter = {} --------\".format(self.reg_param))\n",
    "        print(\"Vanilla Accuracy = {}%\".format(self.vanilla_accuracy))\n",
    "        print(\"Class-Wise Averaged Accuracy = {}%\\n\".format(self.classwise_averaged_accuracy))\n",
    "        return self.classwise_averaged_accuracy\n",
    "    \n",
    "    def execute_on_test(self):\n",
    "        self.init_classifiers()\n",
    "        # Train on both training & validation dataset\n",
    "        self.train()\n",
    "        self.train(on_dataset=\"validate\")\n",
    "        # Test on test dataset\n",
    "        self.test(on_dataset=\"test\")\n",
    "        print(\"-------- TEST SET WITH Regularization Parameter = {} and Kernel Type = {} --------\".format(self.reg_param, self.kernel_type))\n",
    "        print(\"Vanilla Accuracy = {}%\".format(self.vanilla_accuracy))\n",
    "        print(\"Class-Wise Averaged Accuracy = {}%\\n\".format(self.classwise_averaged_accuracy))\n",
    "        \n",
    "\n",
    "reg_params = [0.01, 0.1, 0.1 ** 0.5, 1.0, 10 ** 0.5, 10, 100]\n",
    "best_score = 0\n",
    "best_reg_param = 0\n",
    "for reg_param in reg_params:\n",
    "    binary_svm = BinarySVM(reg_param, \"linear\")\n",
    "    current_score = binary_svm.execute_on_validation()\n",
    "    if current_score > best_score:\n",
    "        best_score = current_score\n",
    "        best_reg_param = reg_param\n",
    "\n",
    "print(\"\\033[1m From validation above, the best regularization paramater is {}\\033[0m\\n\".format(best_reg_param))\n",
    "\n",
    "best_svm_linear = BinarySVM(best_reg_param, \"linear\")\n",
    "best_svm_linear.execute_on_test()\n",
    "\n",
    "best_svm_linear = BinarySVM(best_reg_param, \"rbf\")\n",
    "best_svm_linear.execute_on_test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Two Different Accuracy Measurements\n",
    "\n",
    "### 1) Vanilla Accuracy\n",
    "\n",
    "$$\\frac{1}{n}\\sum_{i=1}^{n}1[f(x_{i})==y_{i}]$$\n",
    "\n",
    "\n",
    "Vanilla accuracy is used to calculate the plain **accuracy score**. We use vanilla accuracy as a **qualitative measure** of SVM, which means a SVM with **higher vanilla accuracy returns MORE correct results relative to the incorrect ones.**\n",
    "\n",
    "### 2) Class-wise Averaged Accuracy\n",
    "\n",
    "$$A = \\frac{1}{C}\\sum_{c=1}^{C}a_{c}$$\n",
    "\n",
    "$$a_{c} = \\frac{1}{\\sum_{i=1}^{n}1[y_{i}==c]}\\sum_{i=1}^{n}1[y_{i}==c]1[f(x_{i})==c]$$\n",
    "\n",
    "$$ = \\frac{1}{\\sum_{(x_{i},y_{i}):y_{i}=c}1}\\sum_{(x_{i},y_{i}):y_{i}=c}1[f(x_{i})==c]$$\n",
    "\n",
    "Meanwhile, class-wise averaged accuracy is used to calculate the **recall score**. We use class-wise average accuracy as a **quantitative measure** of correctness of the SVM, which means a SVM with **higher class-wise averaged accuracy returns most of the correct predictions (regardless of whether the incorrect ones are returned as well)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
